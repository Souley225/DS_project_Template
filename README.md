# ğŸ¯ Template de Projet Data Science

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12-blue?style=for-the-badge&logo=python&logoColor=ffdd54)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)
![Cookiecutter](https://img.shields.io/badge/Cookiecutter-Ready-orange?style=for-the-badge&logo=cookiecutter)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker)

</div>

> **Un template production-ready pour dÃ©marrer vos projets Data Science avec une structure claire, modulaire et reproductible.**

---

## ğŸš€ Pourquoi ce template ?

Ce dÃ©pÃ´t propose une **architecture Ã©prouvÃ©e** pour vos projets Data Science, inspirÃ©e des meilleures pratiques de l'industrie.

### âœ¨ Objectifs

| ğŸ¯ Objectif | ğŸ“ Description |
|------------|---------------|
| **Structure claire** | Organisation logique et intuitive du code |
| **ReproductibilitÃ©** | Configuration centralisÃ©e et versionnÃ©e |
| **MaintenabilitÃ©** | Code modulaire et testable |
| **Production-ready** | PrÃªt pour le dÃ©ploiement (Docker, API, CI/CD) |

---

## ğŸ“‚ Structure du projet

```
ds_project_template/
â”‚
â”œâ”€â”€ ğŸ“¦ components/           # Modules de traitement mÃ©tier
â”‚   â”œâ”€â”€ data_ingestion.py    # Chargement des donnÃ©es
â”‚   â”œâ”€â”€ data_transformation.py # PrÃ©traitement et feature engineering
â”‚   â”œâ”€â”€ model_trainer.py      # EntraÃ®nement des modÃ¨les
â”‚   â””â”€â”€ model_evaluation.py   # Ã‰valuation et mÃ©triques
â”‚
â”œâ”€â”€ ğŸ”„ pipeline/             # Orchestration du workflow
â”‚   â”œâ”€â”€ training_pipeline.py  # Pipeline d'entraÃ®nement
â”‚   â””â”€â”€ prediction_pipeline.py # Pipeline d'infÃ©rence
â”‚
â”œâ”€â”€ ğŸ› ï¸ utils/                # Fonctions utilitaires
â”‚   â”œâ”€â”€ common.py             # Fonctions gÃ©nÃ©riques
â”‚   â””â”€â”€ config_reader.py      # Lecture de configuration
â”‚
â”œâ”€â”€ ğŸ“‹ logger.py             # SystÃ¨me de logs centralisÃ©
â”œâ”€â”€ âš ï¸ exception.py          # Gestion des erreurs
â”‚
â”œâ”€â”€ âš™ï¸ config/
â”‚   â””â”€â”€ config.yaml           # Configuration globale du projet
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ raw/                  # DonnÃ©es brutes
â”‚   â”œâ”€â”€ processed/            # DonnÃ©es transformÃ©es
â”‚   â””â”€â”€ external/             # DonnÃ©es externes
â”‚
â”œâ”€â”€ ğŸ¤– models/               # ModÃ¨les entraÃ®nÃ©s et artefacts
â”œâ”€â”€ ğŸ“ logs/                 # Journaux d'exÃ©cution
â”œâ”€â”€ ğŸ““ notebooks/            # Notebooks d'exploration
â”‚
â”œâ”€â”€ ğŸš€ app.py                # Point d'entrÃ©e API (Flask/FastAPI)
â”œâ”€â”€ ğŸ“¦ requirements.txt      # DÃ©pendances Python
â”œâ”€â”€ ğŸ”§ setup.py              # Configuration du package
â”œâ”€â”€ ğŸ³ Dockerfile            # Containerisation
â””â”€â”€ ğŸ“– README.md             # Documentation
```

---

## ğŸ› ï¸ Installation et utilisation

### Option 1ï¸âƒ£ : Clonage direct

?> **IdÃ©al pour** : DÃ©marrer rapidement un nouveau projet

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/Souley225/DS_project_Template.git

# Renommer selon votre projet
mv DS_project_Template mon_projet_data
cd mon_projet_data

# RÃ©initialiser l'historique Git (optionnel)
rm -rf .git
git init
git add .
git commit -m "ğŸ‰ Initialisation du projet Data Science"
```

### Option 2ï¸âƒ£ : Avec Cookiecutter (recommandÃ©)

!> **RecommandÃ© pour** : GÃ©nÃ©rer des projets personnalisÃ©s avec vos propres paramÃ¨tres

#### Ã‰tape 1 : Installer Cookiecutter

```bash
pip install cookiecutter
```

#### Ã‰tape 2 : GÃ©nÃ©rer le projet

```bash
cookiecutter https://github.com/Souley225/DS_project_Template.git
```

#### Ã‰tape 3 : Configuration interactive

Cookiecutter vous demandera :

| Question | Description | Exemple |
|----------|-------------|---------|
| `project_name` | Nom de votre projet | Customer Churn Prediction |
| `author_name` | Votre nom | Souleymane Sall |
| `description` | Description courte | PrÃ©diction du churn client avec ML |
| `license` | Type de licence | MIT |

---

## ğŸš€ DÃ©marrage rapide

### 1. CrÃ©er l'environnement virtuel

```bash
# CrÃ©ation de l'environnement
python -m venv venv

# Activation
source venv/bin/activate    # Mac/Linux
venv\Scripts\activate       # Windows
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Configuration

Modifiez le fichier `config/config.yaml` selon vos besoins :

```yaml
data:
  raw_path: data/raw/
  processed_path: data/processed/
  
model:
  type: RandomForest
  params:
    n_estimators: 100
    max_depth: 10
    
training:
  test_size: 0.2
  random_state: 42
```

### 4. Lancer le pipeline

```bash
python pipeline/training_pipeline.py
```

---

## ğŸ¨ FonctionnalitÃ©s clÃ©s

### ğŸ“‹ Logging centralisÃ©

```python
from logger import logging

logging.info("DÃ©marrage du traitement des donnÃ©es")
logging.warning("Valeurs manquantes dÃ©tectÃ©es")
logging.error("Erreur lors du chargement du modÃ¨le")
```

### âš ï¸ Gestion des erreurs

```python
from exception import CustomException
import sys

try:
    # Votre code
    pass
except Exception as e:
    raise CustomException(e, sys)
```

### âš™ï¸ Configuration centralisÃ©e

```python
from utils.config_reader import read_config

config = read_config("config/config.yaml")
model_params = config['model']['params']
```

---

## ğŸ”§ Personnalisation avancÃ©e

### ğŸ”„ IntÃ©gration CI/CD

Ajoutez un workflow GitHub Actions dans `.github/workflows/`:

```yaml
name: CI/CD Pipeline
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run tests
        run: pytest tests/
```

### ğŸ“ˆ Suivi des expÃ©riences

IntÃ©grez **MLflow** pour tracker vos expÃ©riences :

```python
import mlflow

with mlflow.start_run():
    mlflow.log_params(model_params)
    mlflow.log_metrics({"accuracy": 0.95})
    mlflow.sklearn.log_model(model, "model")
```

### ğŸ³ DÃ©ploiement Docker

```bash
# Construire l'image
docker build -t mon-projet-ds .

# Lancer le conteneur
docker run -p 8000:8000 mon-projet-ds
```

### ğŸš€ API de prÃ©diction

CrÃ©ez une API avec **FastAPI** dans `app.py` :

```python
from fastapi import FastAPI
from pipeline.prediction_pipeline import predict

app = FastAPI()

@app.post("/predict")
def make_prediction(data: dict):
    return predict(data)
```

---

## ğŸ¯ Cas d'usage

Ce template est parfait pour :

- âœ… **Classification** : Churn prediction, fraud detection, sentiment analysis
- âœ… **RÃ©gression** : Price prediction, demand forecasting, time series
- âœ… **Clustering** : Customer segmentation, anomaly detection
- âœ… **NLP** : Text classification, entity recognition
- âœ… **Computer Vision** : Image classification, object detection

---

## ğŸ“š Ressources complÃ©mentaires

| Ressource | Description |
|-----------|-------------|
| ğŸ”— [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) | Template original et best practices |
| ğŸ”— [MLflow Documentation](https://mlflow.org/docs/latest/index.html) | Suivi d'expÃ©riences ML |
| ğŸ”— [FastAPI](https://fastapi.tiangolo.com/) | Framework API moderne |
| ğŸ”— [Docker Tutorial](https://docs.docker.com/get-started/) | Containerisation |

---

## ğŸ§ª Tests

```bash
# Installation des dÃ©pendances de test
pip install pytest pytest-cov

# Lancer les tests
pytest tests/ -v

# Avec coverage
pytest tests/ --cov=components --cov-report=html
```

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. ğŸ´ Fork le projet
2. ğŸŒ¿ CrÃ©ez une branche (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. ğŸ“¤ Push vers la branche (`git push origin feature/AmazingFeature`)
5. ğŸ”ƒ Ouvrez une Pull Request

---

## ğŸ‘¨â€ğŸ’» Auteur

**Souleymane Sall**

- ğŸ“ Master en Ã‰conomÃ©trie et Statistique AppliquÃ©e
- ğŸ’¼ Data Scientist & MLOps Engineer
- ğŸ’¡ PassionnÃ© par la reproductibilitÃ© et l'industrialisation des modÃ¨les ML

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/souleymanes-sall)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Souley225)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:sallsouleymane2207@gmail.com)

</div>

---

## ğŸ“œ Licence

Ce projet est distribuÃ© sous licence **MIT**.  
Vous Ãªtes libre de l'utiliser, le modifier et le partager.

---

## ğŸŒŸ Remerciements

InspirÃ© par les meilleures pratiques de la communautÃ© Data Science :

- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
- [MLOps Best Practices](https://ml-ops.org/)
- Retours d'expÃ©rience de projets en production

---

<div align="center">

### â­ Si ce template vous est utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !

<sub>Construit avec â¤ï¸ pour la communautÃ© Data Science</sub>

</div>
